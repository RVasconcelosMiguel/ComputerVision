{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVWBIobmhYrBFkQz8zUBWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RVasconcelosMiguel/ComputerVision/blob/main/CV_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tqdm"
      ],
      "metadata": {
        "id": "ohrqiqTYX0Rs",
        "outputId": "42e56f0e-a946-4d76-fe61-862c07880eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm  # Importar tqdm\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam, SGD, NAdam\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torchvision.io import read_image\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from PIL import Image\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "uEQHgJJ0X5YS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "egEVyeavSsNL",
        "outputId": "75c31c44-3137-4e61-dcc8-31699134bcb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model will be running on cpu device\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"The model will be running on\", device, \"device\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "#Limpa arquivos existentes do sistema antes de iniciar as operações.\n",
        "!rm -f -r \"images\"\n",
        "!rm -f \"module_metadada.json\"\n",
        "\n",
        "#Definição de caminhos\n",
        "download_path = \"/content/InfraredSolarModules/\"\n",
        "download_path_file = \"/content/InfraredSolarModules/2020-02-14_InfraredSolarModules.zip\"\n",
        "zip_path = \"/content/2020-02-14_InfraredSolarModules.zip\"\n",
        "extract_path = \"/content\"\n",
        "\n",
        "# Clonar o repositorio e fazer unzip\n",
        "!git clone https://github.com/RaptorMaps/InfraredSolarModules.git $download_path\n",
        "!mv $download_path_file $extract_path\n",
        "!unzip -uq $zip_path -d $extract_path\n",
        "\n",
        "# Imagens\n",
        "image_folder_path = \"/content/InfraredSolarModules/images\"\n",
        "!mv $image_folder_path $extract_path\n",
        "\n",
        "# module_metadata.json\n",
        "metadata_file_path = \"/content/InfraredSolarModules/module_metadata.json\"\n",
        "!mv $metadata_file_path $extract_path\n",
        "\n",
        "#Remoção de arquivos desnecessários\n",
        "!rm -f $zip_path\n",
        "!rm -f -r $download_path\n",
        "!rm -r \"__MACOSX\""
      ],
      "metadata": {
        "id": "-LBuvOx_T7QK",
        "outputId": "00eac4a2-fd30-481b-cf14-35ed0d731f6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/InfraredSolarModules'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 24 (delta 10), reused 12 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (24/24), 5.49 MiB | 15.60 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes_a = (\"anomaly\", \"no-anomaly\")\n",
        "classes_b=(\"cell\",\"cell-multi\",\"cracking\",\"hotspot\",\"hot-spot-multi\",\"shadowing\",\"diode\",\"diode-multi\",\"vegetation\",\"soiling\",\"offlinemodule\")\n",
        "classes_c=(\"cell\",\"cell-multi\",\"cracking\",\"hotspot\",\"hot-spot-multi\",\"shadowing\",\"diode\",\"diode-multi\",\"vegetation\",\"soiling\",\"offlinemodule\",\"no-anomaly\")\n",
        "\n",
        "\n",
        "metadata_path = '/content/module_metadata.json'\n",
        "with open(metadata_path, 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "metadata_df_a = pd.DataFrame.from_dict(metadata, orient='index')\n",
        "metadata_df_b = pd.DataFrame.from_dict(metadata, orient='index')\n",
        "metadata_df_c = pd.DataFrame.from_dict(metadata, orient='index')\n",
        "\n",
        "metadata_df_a['anomaly_class'] = metadata_df_a['anomaly_class'].apply(lambda x: 'Anomaly' if x != 'No-Anomaly' else 'No-Anomaly')\n",
        "metadata_df_b = metadata_df_b[metadata_df_b[\"anomaly_class\"] != \"No-Anomaly\"]\n",
        "\n",
        "print(\"---------a) dataframe------------\")\n",
        "print(\"\\n Data \\n\",metadata_df_a.tail(10))\n",
        "print(\"\\n Data size :\",metadata_df_a.shape[0])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"---------b) dataframe------------\")\n",
        "print(\"\\n Data \\n\",metadata_df_b.tail(10))\n",
        "print(\"\\n Data size :\",metadata_df_b.shape[0])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"---------c) dataframe------------\")\n",
        "print(\"\\n Data \\n\",metadata_df_c.tail(10))\n",
        "print(\"\\n Data size :\",metadata_df_c.shape[0])\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "zxdPk4GBYWLT",
        "outputId": "6f49c2a6-3f27-4429-ff5b-d755fbefe013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------a) dataframe------------\n",
            "\n",
            " Data \n",
            "          image_filepath anomaly_class\n",
            "8483    images/8483.jpg       Anomaly\n",
            "8484    images/8484.jpg       Anomaly\n",
            "8485    images/8485.jpg       Anomaly\n",
            "8486    images/8486.jpg       Anomaly\n",
            "8487    images/8487.jpg       Anomaly\n",
            "8488    images/8488.jpg       Anomaly\n",
            "8489    images/8489.jpg       Anomaly\n",
            "7464    images/7464.jpg       Anomaly\n",
            "18065  images/18065.jpg    No-Anomaly\n",
            "13354  images/13354.jpg    No-Anomaly\n",
            "\n",
            " Data size : 20000\n",
            "\n",
            "\n",
            "---------b) dataframe------------\n",
            "\n",
            " Data \n",
            "        image_filepath anomaly_class\n",
            "8481  images/8481.jpg    Vegetation\n",
            "8482  images/8482.jpg    Vegetation\n",
            "8483  images/8483.jpg    Vegetation\n",
            "8484  images/8484.jpg    Vegetation\n",
            "8485  images/8485.jpg    Vegetation\n",
            "8486  images/8486.jpg    Vegetation\n",
            "8487  images/8487.jpg    Vegetation\n",
            "8488  images/8488.jpg    Vegetation\n",
            "8489  images/8489.jpg    Vegetation\n",
            "7464  images/7464.jpg      Cracking\n",
            "\n",
            " Data size : 10000\n",
            "\n",
            "\n",
            "---------c) dataframe------------\n",
            "\n",
            " Data \n",
            "          image_filepath anomaly_class\n",
            "8483    images/8483.jpg    Vegetation\n",
            "8484    images/8484.jpg    Vegetation\n",
            "8485    images/8485.jpg    Vegetation\n",
            "8486    images/8486.jpg    Vegetation\n",
            "8487    images/8487.jpg    Vegetation\n",
            "8488    images/8488.jpg    Vegetation\n",
            "8489    images/8489.jpg    Vegetation\n",
            "7464    images/7464.jpg      Cracking\n",
            "18065  images/18065.jpg    No-Anomaly\n",
            "13354  images/13354.jpg    No-Anomaly\n",
            "\n",
            " Data size : 20000\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}